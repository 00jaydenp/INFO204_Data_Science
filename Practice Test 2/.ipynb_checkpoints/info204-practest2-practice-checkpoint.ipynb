{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 204 Practical Test 2 Practice Test\n",
    "\n",
    "This notebook provides some expectation towards the types of questions that you may encounter in the practical test - it is not an exact copy of the style of questions that you will be asked in the practical test, but should provide an overview of where you should focus your revision.\n",
    "\n",
    "The practice test has three sections:\n",
    "1. Fitting, interpreting, and optimising k-means clustering\n",
    "2. Supervised learning on text\n",
    "3. Short answer questions\n",
    "\n",
    "Rather than repeat the text here, some sections in this document will ask you to revisit exercises in previous labs. <span style='color: #ce2227'>___YOU ARE STRONGLY ADVISED TO COMPLETE LABS 8 AND 10 AS REVISION FOR THIS TEST___</span>\n",
    "\n",
    "In the test, we will load all the libraries for you, much like we do here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OMP_NUM_THREADS=1\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, classification_report, f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test, YOU WILL NOT NEED TO (NOR SHOULD YOU) LOAD ADDITIONAL LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Clustering\n",
    "\n",
    "The following questions work with the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X, t = wine['data'], wine['target']\n",
    "for c in [  1, 3, 7, 9 ]:\n",
    "    X[:, c] = -X[:, c]\n",
    "\n",
    "feature_names = wine['feature_names']\n",
    "\n",
    "all_data = pd.DataFrame(X, columns=feature_names)\n",
    "all_data['target'] = wine['target_names'][t]\n",
    "\n",
    "display(all_data.describe())\n",
    "\n",
    "sns.pairplot(all_data, hue='target', palette='Set1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 1:</span> Perform a silhouette analysis of k-means clustering on this data set. Consider between 2 and 10 clusters. Produce a plot that compares the number of clusters on the x axis against the silhouette score in the y axis. As part of your analysis, return a variable called `best_clusters` that identifies the number of clusters that produces the best silhouette score. MAKE SURE TO STANDARDISE VARIABLES IF YOU THINK IT'S IMPORTANT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 2:</span> Using the `best_clusters` identified in the previous task, perform k-means clustering on this data set and extract the cluster centroid into a data frame. Add a `cluster` column to the data frame that indicates a unique identifer for each row (i.e., each cluster centroid). Use this data frame to produce a parallel coordinates plot of these centroids, coloured by the cluster label. Then briefly describe the the nature of the cluster centers (e.g., features that tend to produce good cluster separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___WRITE YOUR ANSWER HERE___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning with Text\n",
    "\n",
    "Here, you will revisit the SPAM classification problem from Lab 10. Load the data in and split the data into 70% training and 30% testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE (IN THE TEST THIS WILL BE PROVIDED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also make use of this function to more easily plot the results of cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cv_results(cv, tfidf_name='tfidf', dimred_name='dimred'):\n",
    "    results = pd.DataFrame(cv.cv_results_)\n",
    "\n",
    "    tfidf_columns = results.columns[results.columns.str.match(f'param_{tfidf_name}')]\n",
    "    dimred_columns = results.columns[results.columns.str.match(f'param_{dimred_name}__n_components')]\n",
    "    id_vars = np.concatenate([ tfidf_columns, dimred_columns ])\n",
    "\n",
    "    score_columns = results.columns[results.columns.str.match('split.+_test_score')]\n",
    "\n",
    "    results = results.melt(id_vars=id_vars, value_vars=score_columns, value_name='score')\n",
    "    results.columns = results.columns.str.removeprefix('param_')\n",
    "    results.columns = results.columns.str.removeprefix(f'{dimred_name}__')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 3:</span> Construct a Pipeline that contains two steps - a step called `'bow'` that uses a `CountVectorizer` to convert text into a bag of words representation, and a second step that uses a `LogisticRegression` to perform classification. Using `cross_val_score`, along with the required resources (e.g., `KFold` to determine the number of cross valiation folds, and a suitable scorer that takes into account the underlying class distribution), determine the mean cross validation performance performance of this pipline on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 4:</span> Extend the pipeline from the previous task such that it includes a step for feature extracttion via TF-IDF, and then a dimension reduction using a `TruncatedSVD`. Name these new steps `'tfidf'` and `'dimred'`. This pipeline will need tuning, so create a tuning grid that examines: whether or not to use a `TfIdfTransformer` in the `'tfidf'` step; and the number of components `n_components` within a `TruncatedSVD` operation sitting within the `dimred` step (explore the number of components [1, 3, 7, 15, 31, 62, 125, 250, 500]). Finally, use `GridSearchCV` object to tune and fit a model against our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 5:</span> Use the provided `extract_cv_results` function to produce a data frame from the cross validation results in the previous step. Use this data frame to produce a line plot that plots the number of components used in the x axis against mean cross validation score in the y axis. Colour this plot according to whether or not TF-IDF was used or not. Finally, add a horizontal line to this plot that shows the performance of the pipeline from Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 6:</span> Extract the best estimator pipeline identified by cross validation in Task 4. From this pipeline, extract the `CountVectorizer` used at the `'bow'` step, and the `TruncatedSVD` object used at the `'dimred'` step. Use the `explained_variance_ratio_` array of the pipeline's `TruncatedSVD` object to explain the amount of feature variance captured by this model, and print the length of the vocabulary of the pipeline's `CountVectorizer` object. Finally, obtain the test predictions of the best estimator, and use these predictions within a `classification_report` and `confusion_matrix` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color: #ce2227'>TASK 7:</span> Comment on the performance variation between using TF-IDF and not, along with the number of components used by the pipeline in Tasks 4-6, relative to the performance of the pipeline used in Task 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___WRITE YOUR ANSWER HERE___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Short Answer Questions:\n",
    "\n",
    "Topics that may be explored in this section will come from Lectures 15-17, 19, and 21-22, such as:\n",
    "1. TF-IDF, how it works, and its main goal (Lecture 21)\n",
    "2. The purpose of word embeddings against a bag of words-like representation (Lecture 22)\n",
    "3. Bias and variance in supervised learning, and their relationship to bagging and boosting (Lecture 19)\n",
    "4. When should (or shouldn't) standardisation be used in unsupervised learning, such as k-means clustering or PCA\n",
    "5. What are principal components? Why might it be possible to reduce the number of dimensions of a problem using PCA and not reduce classification or regression performance?\n",
    "6. What is the relationship between PCA as used in the eigenfaces problem, and the layers of a convolutional neural network? (thinking back to Lecture 13 and Lab 7 for this may help)\n",
    "\n",
    "Don't forget to check the tutorials related to these lectures for information that may help with answering these questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('info204')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cee10d90c8bacaf9909a99546f7b02b34bbd8407eebea03a6d2ead7eeabc0dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

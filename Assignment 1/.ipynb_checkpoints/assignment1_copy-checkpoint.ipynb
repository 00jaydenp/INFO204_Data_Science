{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbd8f27-9a1c-4804-962e-1392a6dadb92",
   "metadata": {},
   "source": [
    "# Assignment 1 - Jayden Prakash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e731d5-f542-49b5-82df-0e5832e25ed3",
   "metadata": {},
   "source": [
    "## Part 1 - Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ee24d-8d14-4eac-81fe-0d999036a9c5",
   "metadata": {},
   "source": [
    "#### <b>Question 1</b> - What is supervised learning? What are two purposes/goals? How do these different goals change our approach?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d890a2-b71e-43b5-96c6-3d76d35b03f6",
   "metadata": {},
   "source": [
    "Supervised learning is a form of machine learning where we use a given set of inputs and outputs  to predict a new set of outputs given a new set of inputs. Previous data is usually used in order to train the algorithm in order to provide accurate predictions. One of the purposes of supervised learning is to classify data based on models which have been developed already and the other purpose is to make predictions of future outcomes based on these models. If you are wanting to predict a discrete variable such as if Something is 1 or 0, you would use a classifcation model, however if you were wanting to predict outcomes based on models or parameters you would use regression as these provide continuous variables which are usually used in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18714a-073b-4c8d-a00e-820411f83cf4",
   "metadata": {},
   "source": [
    "#### <b> Question 2 </b> - How do obtain insights about a problem using linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b09a82-9b88-41cb-990b-0ca68b28f88a",
   "metadata": {},
   "source": [
    "Linear regression is what is known as a parametric model. A parametric model learns from the parameters that describe the problem radther than predicting from past instances, as such the predictions are informed by the parameters. Linear regression uses two types of variables, the dependent variable which is what is being measured and the independent variables which is what is used to predict. Its represented by a linear equation that takes a given set of inputs that produce a solution which is the predicted output for that set of inputs. The equation assigns coefficients for each input value that is a scale factor and is also accompanied by a bias coefficient. By using this linear equation we are able to find inisghts by predicting a specific value based on its inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6d786-ab20-4a3c-9b8b-139ab7de2091",
   "metadata": {},
   "source": [
    "#### <b> Question 3 </b> - What is cross validation? How does cross validation obtain an honest estimate of performance? What is one drawback?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005e4de-7d23-49fd-b5ac-c7570143c4b6",
   "metadata": {},
   "source": [
    "Cross validation is a method to measure or evaluate learning models. It obtains an honest estimate by using K-fold cross validation where for a set of data you specify <b><i> k </i></b> folds, and each instance of data is mapped to a fold. Then for each fold, you take out the data that is mapped to it, and use the remaning data to train the model; once that is done you may use the data that you held out earlier to test the data. This is honest because it was tested on data that was not used in training. It is good because it uses the entire dataset instead of just some of it, one big drawback however is that it is quite computationally expensive, requiring you to run it <b> (k * r) + 1 </b> times per model where r is the number of times you need to repeat to assign data to folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef062eb-db4a-410c-a3c1-7c3f1d2bd435",
   "metadata": {},
   "source": [
    "## Part 2 - Data Wrangling and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25073b51-16d1-4b83-b870-7980087d2c5f",
   "metadata": {},
   "source": [
    "Import neccesary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2af2f9-1278-4648-9053-bc799e57d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.correlation import plot_corr\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RepeatedKFold\n",
    "from sklearn.metrics import  r2_score\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad25d259-eb03-4406-9ae6-618e6ccfe398",
   "metadata": {},
   "source": [
    "Import CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce358a-42d0-4a92-906a-e7a66df0e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_measurements = pd.read_csv('measurements.csv')\n",
    "visits = pd.read_csv('site_visits.csv')\n",
    "sites = pd.read_csv('water_quality_sites.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451aee51-ee23-436a-bf1f-ecf8ec23925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert measurements.csv from long to wide\n",
    "measurements = long_measurements.pivot(index ='checksum', columns='Measurement', values ='Value').reset_index()\n",
    "\n",
    "\n",
    "measurements.info()\n",
    "sns.heatmap(measurements.corr());\n",
    "measurements.dropna( inplace=True)\n",
    "measurements.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4156f-7e00-4444-9420-6bd9cb764d02",
   "metadata": {},
   "source": [
    "#### Describe contents of Measurements Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a271c-8ac3-44f8-9fe9-add746ea3e9a",
   "metadata": {},
   "source": [
    "For the measurements dataframe, after converting to wide format and dropping the checksum column, there are 14 columns and a total of 29187 rows prior to dropping the NA value; there were also NA values in every single column prior to dropping them. Each column has a datatype as a decimal as they are all measuresments. After dropping the NA values the number of rows increase to 13219.\n",
    "\n",
    "There also may be an issue when it comes to the scale of the datasets as the minimum and maximum values differ greatly between the different columns. THis will create problems for models such as kNN where standardisation will need to be used.\n",
    "\n",
    "The correlation heatmap shows some very interesting correlations especially between pH and the Absorbance Coefficient, as well as the Dissolved Oxygen Saturation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3172cd-4348-4632-8a60-63692742026a",
   "metadata": {},
   "source": [
    "#### Variable Removal Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148579ac-43d6-4561-9270-6b81db6248a9",
   "metadata": {},
   "source": [
    "For the visits dataframe, I decided to remove the  scientist column as it did not tell us anything useful for modelling purposes as its a non-descriptive non-measurement field and if we are to measure variables by site data, the scientist that took the measure is irrelevant. I also decided to remove days of the week as it is a human construct and a machine would not know the difference between the days of the week so it is useless. Verified by column was removed as it was singular and every single row had the same value meaning the entropy was 0 and it was not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e194f-0ee2-4abc-8ec0-739ef12f66e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visits = visits.drop([ 'Day of Week', 'Verified By', 'Scientist'], axis = 1)\n",
    "visits.info()\n",
    "visits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5d06f-6eeb-4363-9d70-5f80fdd61e9f",
   "metadata": {},
   "source": [
    "##### Describe contents of Visits Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ca86f-95b0-4c08-a025-c883b42c3651",
   "metadata": {},
   "source": [
    "The data types for vists data frame are objects represented as strings and include timestamp and site infomration such as the ID of the site, there are no missing values and there is 29187 rows and 3 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd46ed-3686-45ec-beb7-a6f1b598b007",
   "metadata": {},
   "source": [
    "#### Variable Removal Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cce5cc-dc13-4676-b649-8477015c9cd6",
   "metadata": {},
   "source": [
    "For the sites data frame, most of the columns describe site data, I decided to remove catchment area and catchment height as well as altitude as the name of the site and the coordinates made the other values redundant for modelling and descriptive purposes, we just need the basic site data, as specified by the EColi measurements example. SiteID was not removed from this dataframe despite it being included in vists as it was needed to succesfully merge the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ebf8ac-9c32-44ce-ad3c-5de032203205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sites = sites.drop(['Altitude', 'Catchment area', 'Catchment height'], axis = 1)\n",
    "            \n",
    "sites.info()\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d8143-1cc7-4c15-b198-7190c58d1b4c",
   "metadata": {},
   "source": [
    "There are 5 columns in the quality dataframe,  with a mixture of decimals and strings as object types. Out of 77 entries none of them are null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f1a53-bc31-4f1a-b4da-5fb52bcfc309",
   "metadata": {},
   "source": [
    "#### Combine Dataframes into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaa8b4-02e6-4c62-b439-85a3e223495b",
   "metadata": {},
   "source": [
    "After merging, I removed the \"checksum\" column as it was only neccesary for merging, and does not provide any insights or data when it comes to modelling specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ced0c-3a2d-40c0-a952-3783c138f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = sites.merge(visits)\n",
    "\n",
    "\n",
    "cdf= cdf.merge(measurements, how='inner')\n",
    "cdf = cdf.drop('checksum', axis = 1)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd8b79-8cbc-4918-a156-c06d16b1d5c3",
   "metadata": {},
   "source": [
    "#### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf3527-0f82-4e4f-96e1-026e444d0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cdf.corr());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a59c3-54fe-418c-8b4b-3beda74899b1",
   "metadata": {},
   "source": [
    "#### Extract E-Coli Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df61396-3abc-4660-8d0d-8c9acb3d8668",
   "metadata": {},
   "source": [
    "In this section i will rite code to extract E coli readings greater than 550 per 100ml, I will group them by the appropriate site data, I will then aggregate them by counting the number of instances in each group and write the resulting aggregated data to a csv file sorted by count of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073e1f7-4807-4ece-9138-452cffae1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli = cdf[cdf['E Coli'] >= 550.0][['SiteID', 'Region', 'Name', 'Longitude', 'Latitude', 'E Coli']]\n",
    "ecoli\n",
    "\n",
    "\n",
    "edict = ecoli[\"SiteID\"].value_counts()\n",
    "edict = edict.to_dict()\n",
    "ecoli[\"E Coli\"] = ecoli[\"SiteID\"].map(edict).drop_duplicates(subset=\"SiteID\")\n",
    "\n",
    "\n",
    "ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1fc90-6894-4f05-b999-48f4ee6dc36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
